{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAqVRK8NvJTc"
      },
      "source": [
        "# **Exploratory Data Analysis (EDA)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Face Mask dataset contains 853 images belonging to the 3 classes, as well as their bounding boxes in the PASCAL VOC format. With this dataset, it is possible to create a model to detect people wearing masks, not wearing them, or wearing masks improperly.\n",
        "\n",
        "The classes are:\n",
        "\n",
        "- With mask;\n",
        "- Without mask;\n",
        "- Mask worn incorrectly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j4D6A0DEvu-u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import ast\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaSW0496vKjO",
        "outputId": "cbbb645c-565e-4c64-e3d4-50a9b8a31072"
      },
      "outputs": [],
      "source": [
        "folder_path = f\"dataset/images\"\n",
        "images_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "folder_path = f\"dataset/annotations\"\n",
        "annotation_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "print(f\"There are {len(images_files)} images and {len(annotation_files)} annotation files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EEEgu1WuvSVO"
      },
      "outputs": [],
      "source": [
        "\n",
        "columns = ['img_name','id','boxes', 'label','width','height']\n",
        "dataset = pd.DataFrame(columns=columns)\n",
        "\n",
        "for i, f in enumerate(annotation_files):\n",
        "  path=f\"dataset/annotations/\"+f\n",
        "  tree = ET.parse(path)\n",
        "  root = tree.getroot()\n",
        "  img_name = root.find('filename').text\n",
        "  id=img_name.split('.')[0]\n",
        "  image_width = int(root.find('size/width').text)\n",
        "  image_height = int(root.find('size/height').text)\n",
        "\n",
        "  # Extraire les dÃ©tails de chaque objet\n",
        "  objects = []\n",
        "  labels=[]\n",
        "  for obj in root.findall('object'):\n",
        "\n",
        "    object_label = obj.find('name').text\n",
        "    bbox = obj.find('bndbox')\n",
        "    object_bbox = {\n",
        "        'xmin': int(bbox.find('xmin').text),\n",
        "        'ymin': int(bbox.find('ymin').text),\n",
        "        'xmax': int(bbox.find('xmax').text),\n",
        "        'ymax': int(bbox.find('ymax').text)\n",
        "    }\n",
        "    labels.append(object_label)\n",
        "    objects.append(object_bbox)\n",
        "\n",
        "  data_tuple = (img_name,id, objects,labels,image_width,image_height)\n",
        "  dataset.loc[i] = data_tuple\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "rBInfRDfvVjO",
        "outputId": "13a2dc50-9548-436a-b58d-da1ce591be09"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "eWLZqJUXvX2J",
        "outputId": "a8d3f836-f72f-4cbb-c2e8-f61834f2ab88"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH=f'dataset/images/'\n",
        "dataset['path'] = dataset.apply(lambda row: TRAIN_PATH + str(row.img_name), axis=1)\n",
        "# Get image level labels\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "AFgjvUcIvecz",
        "outputId": "5e05ecb8-4e20-4850-af28-a73acd8a2b95"
      },
      "outputs": [],
      "source": [
        "def map_values_to_labels(input_list, label_mapping):\n",
        "    return [label_mapping[value] for value in input_list]\n",
        "\n",
        "label_mapping = {\n",
        "    'with_mask': 0,\n",
        "    'without_mask': 1,\n",
        "    'mask_weared_incorrect': 2\n",
        "}\n",
        "\n",
        "def map_values_to_labels(input_list, label_mapping):\n",
        "    return [label_mapping[value] for value in input_list]\n",
        "def mapping(row):\n",
        "    label=(row.label)\n",
        "    return map_values_to_labels(label, label_mapping)\n",
        "dataset['numeric_labels'] = dataset.apply(lambda row: mapping(row), axis=1)\n",
        "dataset['n_annotations'] = dataset['boxes'].apply(len)\n",
        "dataset['has_annotations'] = dataset['n_annotations'] > 0\n",
        "dataset['has_2_or_more_annotations'] = dataset['n_annotations'] >= 2\n",
        "dataset['doesnt_have_annotations'] = dataset['n_annotations'] == 0\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FJ5H_8oEvhWC",
        "outputId": "1e54645a-8c50-42bc-ea58-327ec18f53de"
      },
      "outputs": [],
      "source": [
        "df_split  = dataset.groupby(\"img_name\").agg({'has_annotations': 'max'}).astype(int).reset_index()\n",
        "df_split.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hXy_5yBZvlxF"
      },
      "outputs": [],
      "source": [
        "def analize_split(df_train, df_val, df):\n",
        "     # Analize results\n",
        "    print(f\"   Train images                 : {len(df_train) / len(df):.3f}\")\n",
        "    print(f\"   Val   images                 : {len(df_val) / len(df):.3f}\")\n",
        "    print()\n",
        "    print(f\"   Train images with annotations: {len(df_train[df_train['has_annotations']]) / len(df[df['has_annotations']]):.3f}\")\n",
        "    print(f\"   Val   images with annotations: {len(df_val[df_val['has_annotations']]) / len(df[df['has_annotations']]):.3f}\")\n",
        "    print()\n",
        "    print(f\"   Train mean annotations       : {df_train['n_annotations'].mean():.3f}\")\n",
        "    print(f\"   Val   mean annotations       : {df_val['n_annotations'].mean():.3f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6XmZvxKvo8G"
      },
      "outputs": [],
      "source": [
        "!mkdir train-validation-split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88VKhMNQvoTh",
        "outputId": "37f0291b-fbf8-4db1-8a4d-b059ba77a057"
      },
      "outputs": [],
      "source": [
        "# Train validation split\n",
        "from sklearn.model_selection import train_test_split\n",
        "for test_size in [0.05,0.1,0.2]:\n",
        "    print(f\"Generating train-validation split with {test_size*100}% validation\")\n",
        "    df_train_idx, df_val_idx = train_test_split(df_split['img_name'], stratify=df_split[\"has_annotations\"], test_size=test_size, random_state=42)\n",
        "    dataset['is_train'] = dataset['img_name'].isin(df_train_idx)\n",
        "    df_train, df_val = dataset[dataset['is_train']], dataset[~dataset['is_train']]\n",
        "\n",
        "    analize_split(df_train, df_val, dataset)\n",
        "\n",
        "    # Save to file\n",
        "    f_name = f\"train-validation-split/train-{test_size}.csv\"\n",
        "    print(f\"Saving file to {f_name}\")\n",
        "    dataset.to_csv(f_name, index=False)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "3W4GXPNjv-90",
        "outputId": "c5012e39-e9aa-4999-f4c4-e27f54ef8d1d"
      },
      "outputs": [],
      "source": [
        "#Show example \n",
        "from yolo_utils import load_image, show_img\n",
        "dataset=pd.read_csv('train-0.1.csv')\n",
        "i=99\n",
        "img=load_image(dataset['path'].iloc[i])\n",
        "bounding_boxes=ast.literal_eval(dataset['boxes'].iloc[i])\n",
        "bboxes=list([[box['xmin'], box['ymin'], box['xmax'], box['ymax']] for box in bounding_boxes])\n",
        "display(show_img(img, bboxes=bboxes,names=ast.literal_eval(dataset['label'].iloc[i]),labels=ast.literal_eval(dataset['numeric_labels'].iloc[i]),confs=None, bbox_format='voc_pascal',show_classes = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Show example detected by Yolo\n",
        "from yolo_utils import load_image, show_img, predict\n",
        "import torch\n",
        "ckpt_path = 'weights/face_mask_yolov5l'\n",
        "model = torch.hub.load('yolov5','custom',path=ckpt_path,source='local',force_reload=True)\n",
        "conf      = 0.5\n",
        "iou       = 0.5\n",
        "model.conf = conf  # NMS confidence threshold\n",
        "model.iou  = iou  # NMS IoU threshold\n",
        "\n",
        "path = \"yolo_dataset/images/valid/maksssksksss696.png\"\n",
        "img=load_image(path)\n",
        "bboxes, confis,names,labels = predict(model, img, size=640,)\n",
        "display(show_img(img, bboxes=bboxes,names=names,labels=labels,confs=None, bbox_format='voc_pascal',show_classes = True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pfe",
      "language": "python",
      "name": "pfe"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
